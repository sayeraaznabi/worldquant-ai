{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from IPython.display import VimeoVideo\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete to the create a client to connect to the MongoDB server, assigns the \"air-quality\" database to db, and assigned the \"nairobi\" connection to nairobi\n",
    "client = MongoClient(host='localhost', port=27017)\n",
    "db = client[\"air-quality\"]\n",
    "nairobi = db[\"nairobi\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change your wrangle function so that it has a resample_rule argument that allows the user to change the resampling interval. The argument default should be \"1H\"\n",
    "def wrangle(collection, resample_rule=\"1H\"):\n",
    "\n",
    "    results = collection.find(\n",
    "        {\"metadata.site\": 29, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "\n",
    "    # Read results into DataFrame\n",
    "    df = pd.DataFrame(list(results)).set_index(\"timestamp\")\n",
    "\n",
    "    # Localize timezone\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Nairobi\")\n",
    "\n",
    "    # Remove outliers\n",
    "    df = df[df[\"P2\"] < 500]\n",
    "\n",
    "    # Resample and forward-fill\n",
    "    y = df[\"P2\"].resample(resample_rule).mean().fillna(method=\"ffill\")\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your wrangle function to read the data from the nairobi collection into the Series y\n",
    "y=wrangle(nairobi)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an ACF plot for the data in y. Be sure to label the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\"\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_acf(y, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an PACF plot for the data in y. Be sure to label the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\"\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_pacf(y, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training set y_train that contains only readings from October 2018, and a test set y_test that contains readings from November 1, 2018.\n",
    "y_train = y[\"2018-10-01\":\"2018-10-31\"]\n",
    "y_test = y[\"2018-11-01\":\"2018-11-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the baseline mean absolute error for your model.\n",
    "y_pred_baseline = [y_train.mean()]*len(y_train)\n",
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "print(\"Mean P2 Reading:\", round(y_train.mean(), 2))\n",
    "print(\"Baseline MAE:\", round(mae_baseline, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ranges for possible  𝑝  and  𝑞  values. p_params should range between 0 and 25, by steps of 8. q_params should range between 0 and 3 by steps of 1.\n",
    "p_params = range(0,25,8)\n",
    "q_params = range(0,3,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(p_params)\n",
    "list(q_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for p in p_params:\n",
    "        for q in q_params:\n",
    "            order=(p,0,q)\n",
    "            start_time=time.time()\n",
    "            #train model\n",
    "            model=ARIMA(y_train, order=order).fit()\n",
    "            elapsed_time=round(time.time()-start_time,2)\n",
    "            print(f\"Trained ARIMA model {order} in {elapsed_time} seconds\")\n",
    "            #generate in-sample predictions\n",
    "            y_pred=model.predict()\n",
    "            #Calculate training MAE\n",
    "            mae=mean_absolute_error(y_train, y_pred)\n",
    "            print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty dictionary for MAE values\n",
    "mae_grid={}\n",
    "for p in p_params:\n",
    "    #create new key in dict with empty list\n",
    "    mae_grid[p]=[]\n",
    "    for q in q_params:\n",
    "            #set the hyperparameters for the model\n",
    "            order=(p,0,q)\n",
    "            #start_timing\n",
    "            start_time=time.time()\n",
    "            #train model\n",
    "            model=ARIMA(y_train, order=order).fit()\n",
    "            #calculate elapsed time\n",
    "            elapsed_time=round(time.time()-start_time,2)\n",
    "            print(f\"Trained ARIMA model {order} in {elapsed_time} seconds\")\n",
    "            #generate in-sample predictions\n",
    "            y_pred=model.predict()\n",
    "            #Calculate training MAE\n",
    "            mae=mean_absolute_error(y_train, y_pred)\n",
    "            #Add mae to dictionary\n",
    "            mae_grid[p].append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the code below to train a model with every combination of hyperparameters in p_params and q_params. Every time the model is trained, the mean absolute error is calculated and then saved to a dictionary. If you're not sure where to start, do the code-along with Nicholas!\n",
    "# Create dictionary to store MAEs\n",
    "mae_grid = dict()\n",
    "# Outer loop: Iterate through possible values for `p`\n",
    "for p in p_params:\n",
    "    # Create key-value pair in dict. Key is `p`, value is empty list.\n",
    "    mae_grid[p] = list()\n",
    "    # Inner loop: Iterate through possible values for `q`\n",
    "    for q in q_params:\n",
    "        # Combination of hyperparameters for model\n",
    "        order = (p, 0, q)\n",
    "        # Note start time\n",
    "        start_time = time.time()\n",
    "        # Train model\n",
    "        model = ARIMA(y_train, order=order).fit()\n",
    "        # Calculate model training time\n",
    "        elapsed_time = round(time.time() - start_time, 2)\n",
    "        print(f\"Trained ARIMA {order} in {elapsed_time} seconds.\")\n",
    "        # Generate in-sample (training) predictions\n",
    "        y_pred = model.predict()\n",
    "        # Calculate training MAE\n",
    "        mae = mean_absolute_error(y_train, y_pred)\n",
    "        # Append MAE to list in dictionary\n",
    "        mae_grid[p].append(mae)\n",
    "        \n",
    "print(mae_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize all the MAE's from above in a DataFrame names mae_df. Each row represents a possible value for  𝑞  and each column represents a possible value for  𝑝\n",
    "mae_df= pd.DataFrame(mae_grid)\n",
    "mae_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap of the values in mae_grid. Be sure to label your x-axis \"p values\" and your y-axis \"q values\"\n",
    "sns.heatmap(mae_df, cmap=\"Blues\")\n",
    "plt.xlabel(\"p values\")\n",
    "plt.ylabel(\"q values\")\n",
    "plt.title(\"ARMA Grid Search (Criterion:MAE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the plot_diagnostics method to check the residuals for your model. Keep in mind that the plot will represent the residuals from the last model you trained, so make sure it was your best model, too!\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "model.plot_diagnostics(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the code below to perform walk-forward validation for your model for the entire test set y_test. Store your model's predictions in the Series y_pred_wfv. Choose the values for  𝑝  and  𝑞  that best balance model performance and computation time. Remember: This model is going to have to train 24 times before you can see your test MAE!\n",
    "y_pred_wfv = pd.Series()\n",
    "history = y_train.copy()\n",
    "for i in range(len(y_test)):\n",
    "    model = ARIMA(history, order=(8,0,1)).fit()\n",
    "    next_pred = model.forecast()\n",
    "    y_pred_wfv = y_pred_wfv.append(next_pred)\n",
    "    history = history.append(y_test[next_pred.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, generate the list of training predictions for your model. Next, create a DataFrame df_predictions with the true values y_test and your predictions y_pred_wfv (don't forget the index). Finally, plot df_predictions using plotly express. Make sure that the y-axis is labeled \"P2\"\n",
    "df_predictions = pd.DataFrame({\"y_test\": y_test, \"y_pred_wf\":y_pred})\n",
    "fig = px.line(df_predictions, labels={\"value\": \"PM2.5\"})\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
